<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>City of Wings</title><link href="https://city.shaform.com/en/" rel="alternate"></link><link href="https://city.shaform.com/feeds/all.atom.xml" rel="self"></link><id>https://city.shaform.com/en/</id><updated>2017-10-23T21:30:00+08:00</updated><entry><title>Install TensorFlow and Caffe on Ubuntu 16.04 with Anaconda</title><link href="https://city.shaform.com/en/blog/2017/10/23/install-tensorflow-and-caffe-on-ubuntu.html" rel="alternate"></link><published>2017-10-23T21:30:00+08:00</published><updated>2017-10-23T21:30:00+08:00</updated><author><name>Shaform</name></author><id>tag:city.shaform.com,2017-10-23:/en/blog/2017/10/23/install-tensorflow-and-caffe-on-ubuntu.html</id><summary type="html">&lt;p&gt;Previously I have written about &lt;a href="https://city.shaform.com/en/../blog/2016/10/31/install-tensorflow-with-cuda.html"&gt;在Ubuntu 安裝 TensorFlow 的紀錄 (Installing
TensorFlow on Ubuntu)&lt;/a&gt;.  Years have passed, and even though
Ubuntu is still on 16.04，TensorFlow has
already made great progress.  I've decided to write another post to show how to
install TensorFlow and Caffe with Anaconda.&lt;/p&gt;
&lt;h2&gt;GPU Settings&lt;/h2&gt;
&lt;h3&gt;Basic …&lt;/h3&gt;</summary><content type="html">&lt;p&gt;Previously I have written about &lt;a href="https://city.shaform.com/en/../blog/2016/10/31/install-tensorflow-with-cuda.html"&gt;在Ubuntu 安裝 TensorFlow 的紀錄 (Installing
TensorFlow on Ubuntu)&lt;/a&gt;.  Years have passed, and even though
Ubuntu is still on 16.04，TensorFlow has
already made great progress.  I've decided to write another post to show how to
install TensorFlow and Caffe with Anaconda.&lt;/p&gt;
&lt;h2&gt;GPU Settings&lt;/h2&gt;
&lt;h3&gt;Basic&lt;/h3&gt;
&lt;p&gt;Firstly set integrated video card as the main GPU in the BIOS, and connect your
monitor to the output port of the integrated video card so your Nvidia GPU is
completely dedicated to deep learning computation.&lt;/p&gt;
&lt;h3&gt;Install CUDA&lt;/h3&gt;
&lt;p&gt;Afterwards, download the deb files from &lt;a href="https://developer.nvidia.com/cuda-downloads"&gt;the download page of
CUDA&lt;/a&gt;.  Do not install at this time. We would reboot Ubuntu and
enter &lt;code&gt;Ctrl-Alt-F1&lt;/code&gt; to login via terminal.&lt;/p&gt;
&lt;p&gt;Execute the following command to stop &lt;code&gt;lightdm&lt;/code&gt;.&lt;/p&gt;
&lt;div class="sh-highlight"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="hll"&gt;sudo service lightdm stop
&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;


&lt;/div&gt;
&lt;p&gt;According to &lt;a href="https://gist.github.com/bearpaw/c38ef18ec45ba6548ec0"&gt;this article&lt;/a&gt;, this must be done when you want to
use your Nvidia GPU solely for CUDA. When this is not done, we might not be
able to login to the desktop after CUDA installation.&lt;/p&gt;
&lt;p&gt;So now we would install CUDA 8.0.&lt;/p&gt;
&lt;div class="sh-highlight"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="hll"&gt;sudo dpkg -i cuda-repo-&amp;lt;distro&amp;gt;_&amp;lt;version&amp;gt;_&amp;lt;architecture&amp;gt;.deb
&lt;/span&gt;&lt;span class="hll"&gt;sudo apt update
&lt;/span&gt;&lt;span class="hll"&gt;sudo apt install cuda-8-0
&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;


&lt;/div&gt;
&lt;p&gt;Record which version of nvidia driver is installed and add the PATH to &lt;code&gt;.bashrc&lt;/code&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nb"&gt;export&lt;/span&gt; &lt;span class="nv"&gt;LD_LIBRARY_PATH&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nv"&gt;$LD_LIBRARY_PATH&lt;/span&gt;:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/lib/nvidia-384
&lt;span class="nb"&gt;export&lt;/span&gt; &lt;span class="nv"&gt;CUDA_HOME&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;/usr/local/cuda
&lt;span class="nb"&gt;export&lt;/span&gt; &lt;span class="nv"&gt;PATH&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nv"&gt;$PATH&lt;/span&gt;:/usr/local/cuda/bin
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;where &lt;code&gt;/usr/lib/nvidia-384&lt;/code&gt; should point to the actual version installed.&lt;/p&gt;
&lt;p&gt;Reboot again to confirm that we could login:&lt;/p&gt;
&lt;div class="sh-highlight"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="hll"&gt;sudo reboot
&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;


&lt;/div&gt;
&lt;h2&gt;Setup Anaconda Environment&lt;/h2&gt;
&lt;h3&gt;Install Anaconda&lt;/h3&gt;
&lt;p&gt;Download Python 3 version of Anaconda at the &lt;a href="https://www.anaconda.com/download/#linux"&gt;Anaconda download
page&lt;/a&gt;, and execute the installation command:&lt;/p&gt;
&lt;div class="sh-highlight"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="hll"&gt;bash ~/Downloads/Anaconda3-&lt;span class="o"&gt;{&lt;/span&gt;VERSION&lt;span class="o"&gt;}&lt;/span&gt;-Linux-x86_64.sh
&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;


&lt;/div&gt;
&lt;p&gt;Install Anaconda onto a directory such as &lt;code&gt;$HOME/anaconda3&lt;/code&gt;.&lt;/p&gt;
&lt;h3&gt;Create TensorFlow Environment&lt;/h3&gt;
&lt;p&gt;Activate Anaconda:&lt;/p&gt;
&lt;div class="sh-highlight"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="hll"&gt;&lt;span class="nb"&gt;source&lt;/span&gt; &lt;span class="nv"&gt;$HOME&lt;/span&gt;/anaconda3/bin/activate
&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;


&lt;/div&gt;
&lt;p&gt;And create a new environment named &lt;code&gt;tf&lt;/code&gt;:&lt;/p&gt;
&lt;div class="sh-highlight"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="hll"&gt;conda create -n tf anaconda
&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;


&lt;/div&gt;
&lt;p&gt;Finally activate &lt;code&gt;tf&lt;/code&gt; environment:&lt;/p&gt;
&lt;div class="sh-highlight"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="hll"&gt;&lt;span class="nb"&gt;source&lt;/span&gt; activate tf
&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;


&lt;/div&gt;
&lt;h2&gt;Install TensorFlow&lt;/h2&gt;
&lt;p&gt;Execute this command and &lt;code&gt;tensorflow-gpu&lt;/code&gt;, &lt;code&gt;cudnn&lt;/code&gt;, &lt;code&gt;cudatoolkit&lt;/code&gt; would be
installed automatically.
&lt;div class="sh-highlight" markdown="1"&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="hll"&gt;conda install tensorflow-gpu
&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;


&lt;/div&gt;

&lt;h2&gt;Install Caffe&lt;/h2&gt;
&lt;p&gt;Firstly install the required packages:&lt;/p&gt;
&lt;div class="sh-highlight"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="hll"&gt;sudo apt install build-essential
&lt;/span&gt;&lt;span class="hll"&gt;conda install atlas boost gflags glog hdf5 leveldb lmdb openblas protobuf
&lt;/span&gt;&lt;span class="hll"&gt;conda install -c menpo opencv3
&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;


&lt;/div&gt;
&lt;p&gt;Download Caffe, and create the configuration file.&lt;/p&gt;
&lt;div class="sh-highlight"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="hll"&gt;git clone https://github.com/BVLC/caffe
&lt;/span&gt;&lt;span class="hll"&gt;&lt;span class="nb"&gt;cd&lt;/span&gt; caffe
&lt;/span&gt;&lt;span class="hll"&gt;cp Makefile.config.example Makefile.config
&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;


&lt;/div&gt;
&lt;p&gt;Modify &lt;code&gt;Makefile.config&lt;/code&gt;, the number in &lt;code&gt;python3.6&lt;/code&gt; could be
changed to the current Python version:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;5c5
&lt;span class="o"&gt;&amp;lt;&lt;/span&gt; # USE_CUDNN := 1
&lt;span class="gd"&gt;---&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; USE_CUDNN := 1
21c21
&lt;span class="o"&gt;&amp;lt;&lt;/span&gt; # OPENCV_VERSION := 3
&lt;span class="gd"&gt;---&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; OPENCV_VERSION := 3
25c25
&lt;span class="o"&gt;&amp;lt;&lt;/span&gt; # CUSTOM_CXX := g++
&lt;span class="gd"&gt;---&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; CUSTOM_CXX := /usr/bin/g++-4.9
68,69c68,69
&lt;span class="o"&gt;&amp;lt;&lt;/span&gt; PYTHON_INCLUDE := /usr/include/python2.7 \
&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;       /usr/lib/python2.7/dist-packages/numpy/core/include
&lt;span class="gd"&gt;---&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; # PYTHON_INCLUDE := /usr/include/python2.7 \
&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; #         /usr/lib/python2.7/dist-packages/numpy/core/include
72,75c72,75
&lt;span class="o"&gt;&amp;lt;&lt;/span&gt; # ANACONDA_HOME := $(HOME)/anaconda
&lt;span class="o"&gt;&amp;lt;&lt;/span&gt; # PYTHON_INCLUDE := $(ANACONDA_HOME)/include \
&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;       # $(ANACONDA_HOME)/include/python2.7 \
&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;       # $(ANACONDA_HOME)/lib/python2.7/site-packages/numpy/core/include
&lt;span class="gd"&gt;---&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; ANACONDA_HOME := $(HOME)/anaconda3/envs/tf
&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; PYTHON_INCLUDE := $(ANACONDA_HOME)/include \
&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;       $(ANACONDA_HOME)/include/python3.6m \
&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;       $(ANACONDA_HOME)/lib/python3.6/site-packages/numpy/core/include
83,84c83,84
&lt;span class="o"&gt;&amp;lt;&lt;/span&gt; PYTHON_LIB := /usr/lib
&lt;span class="o"&gt;&amp;lt;&lt;/span&gt; # PYTHON_LIB := $(ANACONDA_HOME)/lib
&lt;span class="gd"&gt;---&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; # PYTHON_LIB := /usr/lib
&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; PYTHON_LIB := $(ANACONDA_HOME)/lib
94c94
&lt;span class="o"&gt;&amp;lt;&lt;/span&gt; INCLUDE_DIRS := $(PYTHON_INCLUDE) /usr/local/include
&lt;span class="gd"&gt;---&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; INCLUDE_DIRS := $(PYTHON_INCLUDE)
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Caffe can now be compiled:&lt;/p&gt;
&lt;div class="sh-highlight"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="hll"&gt;make all
&lt;/span&gt;&lt;span class="hll"&gt;make pycaffe
&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;


&lt;/div&gt;</content><category term="TensorFlow"></category><category term="Caffe"></category><category term="CUDA"></category><category term="Ubuntu"></category></entry><entry><title>snappycat: A command line tool to decompress snappy files produced by Hadoop</title><link href="https://city.shaform.com/en/blog/2015/11/06/snappycat.html" rel="alternate"></link><published>2015-11-06T21:20:00+08:00</published><updated>2015-11-06T21:20:00+08:00</updated><author><name>Shaform</name></author><id>tag:city.shaform.com,2015-11-06:/en/blog/2015/11/06/snappycat.html</id><summary type="html">&lt;p&gt;I often encounter [Snappy][]-compressed files recently when I am learning Spark.
Although we could just use &lt;code&gt;sc.textFile&lt;/code&gt; to read them in Spark, sometimes we
might want to download them locally for processing. However, reading these files
locally is complicated because the file format is not exactly Snappy-compressed files …&lt;/p&gt;</summary><content type="html">&lt;p&gt;I often encounter [Snappy][]-compressed files recently when I am learning Spark.
Although we could just use &lt;code&gt;sc.textFile&lt;/code&gt; to read them in Spark, sometimes we
might want to download them locally for processing. However, reading these files
locally is complicated because the file format is not exactly Snappy-compressed files,
        as Hadoop stores those files in its own way.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;    Most of existing solutions use Java to link with Hadoop library, but the setup is
    rather complicated. Moreover, some tools don&amp;#39;t support empty files. Therefore, I
    spent some time to study the file format.

    [Snappy]: https://blog.cloudera.com/blog/2011/09/snappy-and-hadoop/

    In short, Hadoop split the files into multiple blocks, and each block is compressed with
    Snappy independently. Before each compressed block, two 32-bit number are used to represent
    the decompressed size and the compressed size, respectively.

    As Spark split files into multiple partitions, some partitions might be empty. In such cases,
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;the files would only contain two 32-bit 0s.&lt;/p&gt;
&lt;p&gt;I developed a short C++ program to handle these cases: &lt;a href="https://github.com/shaform/snappycat"&gt;snappycat&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The usage is simple, just use input files as arguments:&lt;/p&gt;
&lt;div class="sh-highlight"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="hll"&gt;./snappycat DIRECTORY/*.snappy
&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;


&lt;/div&gt;
&lt;p&gt;It also supports standard input:&lt;/p&gt;
&lt;div class="sh-highlight"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="hll"&gt;cat DIRECTARY/*.snappy &lt;span class="p"&gt;|&lt;/span&gt; snappycat
&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;


&lt;/div&gt;
&lt;p&gt;The program outputs the decompressed result to standard output. So to save the output, use:&lt;/p&gt;
&lt;div class="sh-highlight"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="hll"&gt;./snappycat DIRECTORY/*.snappy &amp;gt; output.txt
&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;


&lt;/div&gt;</content><category term="Hadoop"></category><category term="Spark"></category><category term="snappy"></category><category term="snappycat"></category></entry><entry><title>Using Caffe for Sentiment Analysis</title><link href="https://city.shaform.com/en/blog/2015/06/06/caffe-sentiment-analysis.html" rel="alternate"></link><published>2015-06-06T11:05:00+08:00</published><updated>2015-06-06T11:05:00+08:00</updated><author><name>Shaform</name></author><id>tag:city.shaform.com,2015-06-06:/en/blog/2015/06/06/caffe-sentiment-analysis.html</id><summary type="html">&lt;p&gt;&lt;a href="http://caffe.berkeleyvision.org/"&gt;Caffe&lt;/a&gt; is a deep learning framework that can be used to
develop neural network models. Although Caffe is usually used
for image classification, it does not prevent us from utilizing it
for other tasks. In this article, we outline the procedure to convert
&lt;a href="http://arxiv.org/abs/1405.4053"&gt;Paragraph Vectors&lt;/a&gt; into the &lt;a href="http://symas.com/mdb/"&gt;LMDB&lt;/a&gt; format that …&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;a href="http://caffe.berkeleyvision.org/"&gt;Caffe&lt;/a&gt; is a deep learning framework that can be used to
develop neural network models. Although Caffe is usually used
for image classification, it does not prevent us from utilizing it
for other tasks. In this article, we outline the procedure to convert
&lt;a href="http://arxiv.org/abs/1405.4053"&gt;Paragraph Vectors&lt;/a&gt; into the &lt;a href="http://symas.com/mdb/"&gt;LMDB&lt;/a&gt; format that Caffe understands, and
create a simple model to train and predict the sentiment for movie reviews.&lt;/p&gt;
&lt;h1&gt;Data Preparation&lt;/h1&gt;
&lt;p&gt;While in the &lt;a href="https://city.shaform.com/en/../blog/2015/03/27/sentiment-analysis.html"&gt;previous post&lt;/a&gt; we use custom Chinese corpus
for sentiment analysis, this time we utilize the scripts provided
by &lt;a href="https://github.com/mesnilgr/iclr15"&gt;mesnilgr/iclr15&lt;/a&gt; to download the &lt;a href="http://ai.stanford.edu/~amaas/data/sentiment/"&gt;Large Movie Review Dataset&lt;/a&gt;
so it's easier to reproduce the results.&lt;/p&gt;
&lt;div class="sh-highlight"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# get mesnilgr/iclr15&lt;/span&gt;
&lt;span class="hll"&gt;git clone https://github.com/mesnilgr/iclr15
&lt;/span&gt;
&lt;span class="hll"&gt;mkdir -p iclr15_run
&lt;/span&gt;&lt;span class="hll"&gt;&lt;span class="nb"&gt;cd&lt;/span&gt; iclr15_run
&lt;/span&gt;
&lt;span class="c1"&gt;# get data&lt;/span&gt;
&lt;span class="hll"&gt;../iclr15/scripts/data.sh
&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;


&lt;/div&gt;
&lt;p&gt;Afterwards, we create the &lt;a href="http://arxiv.org/abs/1405.4053"&gt;Paragraph Vectors&lt;/a&gt; for each review. Paragraph
Vectors are fixed-dimensional distributed representations for texts. Once we
convert each review into a vector, we could easily feed it into a neural network.&lt;/p&gt;
&lt;div class="sh-highlight"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# extract the part to create paragraph vectors from iclr15 scripts&lt;/span&gt;
&lt;span class="hll"&gt;sed -e &lt;span class="s1"&gt;&amp;#39;/liblinear/,$d&amp;#39;&lt;/span&gt; ../iclr15/scripts/paragraph.sh &amp;gt; paragraph.sh
&lt;/span&gt;
&lt;span class="c1"&gt;# start creating the vectors&lt;/span&gt;
&lt;span class="hll"&gt;chmod +x paragraph.sh
&lt;/span&gt;&lt;span class="hll"&gt;./paragraph.sh
&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;


&lt;/div&gt;
&lt;p&gt;Finally, we copy the resulting files.&lt;/p&gt;
&lt;div class="sh-highlight"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# copy the vectors&lt;/span&gt;
&lt;span class="hll"&gt;&lt;span class="nb"&gt;cd&lt;/span&gt; word2vec
&lt;/span&gt;&lt;span class="hll"&gt;cp full-train.txt test.txt ../../
&lt;/span&gt;&lt;span class="hll"&gt;&lt;span class="nb"&gt;cd&lt;/span&gt; ../../
&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;


&lt;/div&gt;
&lt;h1&gt;Converting the Input Format&lt;/h1&gt;
&lt;p&gt;We now have two files: &lt;code&gt;full-train.txt&lt;/code&gt; and &lt;code&gt;test.txt&lt;/code&gt; for training and testing
respectively. These files use &lt;a href="https://github.com/cjlin1/libsvm/blob/master/README"&gt;LIBSVM data format&lt;/a&gt;, which can
not be used with Caffe directly. Therefore, we create a script to convert the files.&lt;/p&gt;
&lt;p&gt;We will use utilities provided by &lt;a href="http://caffe.berkeleyvision.org/installation.html#python-andor-matlab-caffe-optional"&gt;Pycaffe&lt;/a&gt; to do the conversion; be sure to install
all the dependencies and Pycaffe itself. Notice that currently Pycaffe does not work
well on Python 3, so we'll use Python 2.7 here. If you don't want to install Pycaffe
system-wide. You could also manually set the &lt;code&gt;PYTHONPATH&lt;/code&gt; variable as follows.&lt;/p&gt;
&lt;div class="sh-highlight"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="hll"&gt;&lt;span class="nb"&gt;export&lt;/span&gt; &lt;span class="nv"&gt;PYTHONPATH&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="si"&gt;${&lt;/span&gt;&lt;span class="nv"&gt;PYTHONPATH&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;:caffe-directory/python/
&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;


&lt;/div&gt;
&lt;p&gt;In addition, install the &lt;a href="http://lmdb.readthedocs.org/en/release/"&gt;py-lmdb&lt;/a&gt; Python package.&lt;/p&gt;
&lt;div class="sh-highlight"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="hll"&gt;sudo pip install lmdb
&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;


&lt;/div&gt;
&lt;p&gt;Each line in the input file begins with a label followed by a 100-dimensional array.
So we extract the data using a simple Python routine.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;random&lt;/span&gt;

&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;np&lt;/span&gt;

&lt;span class="n"&gt;num_of_dims&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;100&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;load_data&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;path&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;items&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;
    &lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="nb"&gt;open&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;path&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;l&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="n"&gt;tokens&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;l&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;rstrip&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;split&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
            &lt;span class="n"&gt;label&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;int&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tokens&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
            &lt;span class="c1"&gt;# change label `-1&amp;#39; to `0&amp;#39;&lt;/span&gt;
            &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;label&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                &lt;span class="n"&gt;label&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;
            &lt;span class="c1"&gt;# ignore the index since we already know the format&lt;/span&gt;
            &lt;span class="n"&gt;arr&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nb"&gt;float&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dim&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;split&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;:&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;dim&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;tokens&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;:]]&lt;/span&gt;
            &lt;span class="n"&gt;items&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;label&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;arr&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;

    &lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shuffle&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;items&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="n"&gt;Y&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;_&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;items&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
    &lt;span class="n"&gt;X&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;_&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;items&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
    &lt;span class="n"&gt;X&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;reshape&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Y&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;num_of_dims&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;

    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Y&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;There is a well-written tutorial on creating LMDB file on
&lt;a href="http://deepdish.io/2015/04/28/creating-lmdb-in-python/"&gt;Creating an LMDB database in Python&lt;/a&gt;, and we'll adopt
a similar procedure. The only difference is that we are using &lt;code&gt;floats&lt;/code&gt;
for the data, so we'll just use &lt;code&gt;array_to_datum&lt;/code&gt; to create the &lt;code&gt;Datum&lt;/code&gt;
for us.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;lmdb&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;caffe.io&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;array_to_datum&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;save_data&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;path&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Y&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt; 
    &lt;span class="n"&gt;num&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;prod&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;itemsize&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;dtype&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;dtype&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;itemsize&lt;/span&gt;
    &lt;span class="c1"&gt;# set a reasonable upper limit for database size&lt;/span&gt;
    &lt;span class="n"&gt;map_size&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;10240&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mi"&gt;1024&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;num&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;itemsize&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt; 
    &lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;save {} instances...&amp;#39;&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;num&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="n"&gt;env&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;lmdb&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;open&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;path&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;map_size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;map_size&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;enumerate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;zip&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Y&lt;/span&gt;&lt;span class="p"&gt;)):&lt;/span&gt;
        &lt;span class="n"&gt;datum&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;array_to_datum&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;str_id&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;{:08}&amp;#39;&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

        &lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="n"&gt;env&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;begin&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;write&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;txn&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="n"&gt;txn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;put&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;str_id&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;datum&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;SerializeToString&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Using the complete &lt;a href="https://github.com/shaform/experiments/blob/master/caffe_sentiment_analysis/convert.py"&gt;convert.py&lt;/a&gt; script, we convert both
training and testing files into LMDB format.&lt;/p&gt;
&lt;div class="sh-highlight"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="hll"&gt;python convert.py full-train.txt movie-train-lmdb
&lt;/span&gt;&lt;span class="hll"&gt;python convert.py test.txt movie-test-lmdb
&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;


&lt;/div&gt;
&lt;h1&gt;Creating a Caffe Model&lt;/h1&gt;
&lt;p&gt;Finally, we create a simple NN model with &lt;a href="https://github.com/shaform/experiments/blob/master/caffe_sentiment_analysis/nn.prototxt"&gt;nn.prototxt&lt;/a&gt; and &lt;a href="https://github.com/shaform/experiments/blob/master/caffe_sentiment_analysis/nn_solver.prototxt"&gt;nn_solver.prototxt&lt;/a&gt;. Execute the
Caffe command line tool and we obtain the following results.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ caffe train --solver=nn_solver.prototxt

Iteration 10000, loss = 0.142478
Iteration 10000, Testing net (#0)
    Test net output #0: accuracy = 0.88364
    Test net output #1: loss = 0.284636 (* 1 = 0.284636 loss)
Optimization Done.
&lt;/pre&gt;&lt;/div&gt;


&lt;h1&gt;Source Code&lt;/h1&gt;
&lt;p&gt;The relevant source code is on &lt;a href="https://github.com/shaform/experiments/blob/master/caffe_sentiment_analysis/"&gt;shaform/experiments/caffe_sentiment_analysis&lt;/a&gt;.&lt;/p&gt;</content><category term="word2vec"></category><category term="Caffe"></category><category term="sentiment analysis"></category><category term="deep learning"></category></entry><entry><title>Google Inbox-like Web Browsing</title><link href="https://city.shaform.com/en/blog/2014/11/07/google-inbox-like-web-browsing.html" rel="alternate"></link><published>2014-11-07T18:52:00+08:00</published><updated>2014-11-07T18:52:00+08:00</updated><author><name>Shaform</name></author><id>tag:city.shaform.com,2014-11-07:/en/blog/2014/11/07/google-inbox-like-web-browsing.html</id><summary type="html">&lt;p&gt;Last time, I explored the idea of designing a web browsing UI that reduces the possibility of distractions in &lt;a href="https://city.shaform.com/en/blog/2013/10/20/single-minded.html"&gt;〈Single-minded : an Internet reader, made for readers, made by readers〉&lt;/a&gt;. While that idea might sound interesting, the design itself was somewhat primitive. Recently, Google has announced &lt;a href="http://www.google.com/inbox/"&gt;Inbox&lt;/a&gt;, a new way to …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Last time, I explored the idea of designing a web browsing UI that reduces the possibility of distractions in &lt;a href="https://city.shaform.com/en/blog/2013/10/20/single-minded.html"&gt;〈Single-minded : an Internet reader, made for readers, made by readers〉&lt;/a&gt;. While that idea might sound interesting, the design itself was somewhat primitive. Recently, Google has announced &lt;a href="http://www.google.com/inbox/"&gt;Inbox&lt;/a&gt;, a new way to handle email. And I find that many ideas behind Inbox are also applicable to web browsing as well.&lt;/p&gt;
&lt;h2&gt;Tabs as Threads&lt;/h2&gt;
&lt;p&gt;For example, different tabs can be represented as different threads, and for each thread, the history can be easily represented as different 'email' in the same thread.&lt;/p&gt;
&lt;p&gt;&lt;img alt="History as emails" src="https://city.shaform.com/en/images/inbox-history.png"&gt;&lt;/p&gt;
&lt;p&gt;Such layout provides better navigation for histories than the current design of 'back' and 'forward' buttons. Sophisticated text summarization techniques can also be used to enable user to get information without actually open that page.&lt;/p&gt;
&lt;h2&gt;Search as Threads&lt;/h2&gt;
&lt;p&gt;Not only a tab can be represented as threads, a search attempt can also utilize the thread layout. We simply click on the empty space, and a search input field would appear. After entering the keywords, we click as many results as we like. Each click results in a different 'email' in the same threads, and we can inspect each one later at any time. We can archive unrelavent pages and decide to mark every remaining results with a label for later use.&lt;/p&gt;
&lt;h2&gt;Unification of History, Bookmarks, and Tabs&lt;/h2&gt;
&lt;p&gt;Indeed, every page marked as done (archived) is just like the old history. Every page on the inbox is just like the tabs. And every page with a label is a bookmark. In this way, we unify everything with a consistent and simple UI. We also drastically increase the possibility for the user to utilize bookmark functions.&lt;/p&gt;
&lt;h2&gt;We Learn Everything, so We Search for You&lt;/h2&gt;
&lt;p&gt;Since we can safely assume that any pages left in the inbox is something that the user is interested in currently. (Otherwise she should have archived it.) We can actively recommend related pages for different threads. Moreover, for those 'search threads', we also have the keywords used, and since the user might try to delete unwanted results from the inbox, we have relevance feedback as well. And latency is no longer an issue, as we can do the search and the show results when the user open the browser next time. So we are able to produce extremely accurate result compared to conventional search engines. And we also have the opportunity to insert related advertisment as well.&lt;/p&gt;
&lt;p&gt;However, if we do use this kind of web browsing, our entire browsing history will be on the cloud. Is this acceptable?&lt;/p&gt;</content><category term="browser"></category><category term="Internet"></category><category term="Google Inbox"></category></entry><entry><title>Single-minded : an Internet reader, made for readers, made by readers</title><link href="https://city.shaform.com/en/blog/2013/10/20/single-minded.html" rel="alternate"></link><published>2013-10-20T20:25:00+08:00</published><updated>2013-10-20T20:25:00+08:00</updated><author><name>Shaform</name></author><id>tag:city.shaform.com,2013-10-20:/en/blog/2013/10/20/single-minded.html</id><summary type="html">&lt;h2&gt;Realization&lt;/h2&gt;
&lt;p&gt;I've known it for a long time that it’s difficult for me to read long articles on the web. I thought it’s because of the screen. It made my eyes get tired so easily. However, when I started to read The Shallows written by Nicholas Carr, I …&lt;/p&gt;</summary><content type="html">&lt;h2&gt;Realization&lt;/h2&gt;
&lt;p&gt;I've known it for a long time that it’s difficult for me to read long articles on the web. I thought it’s because of the screen. It made my eyes get tired so easily. However, when I started to read The Shallows written by Nicholas Carr, I realized that it’s not only the screen. The Internet itself is distracting.&lt;/p&gt;
&lt;p&gt;I started to remember that, I often clicked between different tabs aimlessly. I repeatedly opened and reopened the Facebook page or my email inbox, wasting my time getting nothing. Indeed, I realized that I was so impatient that whenever the browser was loading a new page, I would switch to another tab, because I did not want to wait for it.&lt;/p&gt;
&lt;p&gt;Once I noticed this, I started to think about possible solutions to overcome this problem -- a new way of browsing. If I could get rid of the waiting time, maybe tabs would no longer be needed? If I could get rid of the tabs, maybe the Internet would be less distracting.&lt;/p&gt;
&lt;h2&gt;Single-tasking&lt;/h2&gt;
&lt;p&gt;To focus on one time at a time when browsing, the first thing I would need to change is the bookmarks. Bookmarks are distracting. Whenever I open the browser, I need to choose between different websites, and this decision is difficult to make. Indeed, because those tiny icons always compete for my attention, I get distracted easily and forget my tasks. Instead of choosing between different websites, I should simply choose between Tasks:&lt;/p&gt;
&lt;p&gt;&lt;img alt="Tasks" src="https://lh5.googleusercontent.com/F7oAKl0sAyFqQPubG8gUytcYkQgLJM0LlejSH9SmTIxXB95BZ2_KvyaxXFVFdGErcv9VABjNiV8tRBo0t3vsqKiF7zA-0jxirAgBbBV5kWqmxe8-2N7kvcI0"&gt;&lt;/p&gt;
&lt;p&gt;Each Task is composed of multiple Steps, and each Step has its own history of pages. When I click on one Task, the browser would only display one page: the last viewed page of the first Step.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Step" src="https://lh3.googleusercontent.com/lyQGxP6oxBwAYs-lTUE8ND5oXe0Uo-ryYkLkODjKC9D-HVsGGhP5lFcX_HLbVO4VpSwrwPwCCvpmb9ztOJEQUMLt3NyXrHulMi8r8vleF_0mMIRB0tTSIGJs"&gt;&lt;/p&gt;
&lt;p&gt;It shouldn't be allowed to open two Tasks at the same time. I must complete one Task before I can go to the home page again. This makes me focus on one thing at a time.&lt;/p&gt;
&lt;h2&gt;Never Going Back&lt;/h2&gt;
&lt;p&gt;When I am in a Step, I can go back and forth through history within the Step as usual. But once I proceed to the next Step, there is no going back. This design forces me to focus on one Step at a time and encourages me to complete one Step before I go on to the next. But of course, sometimes I may want to read some other references before I can complete a Step. In this case, I can push the current Step to the end of the current Task, so I can come back to it later. By pushing everything to the end, I can actually keep every Step open, but even in this case, a linear flow is still maintained.&lt;/p&gt;
&lt;h2&gt;New Steps&lt;/h2&gt;
&lt;p&gt;Since I have no tabs, I cannot open a new page in a different tab. Instead, I open it in the current Step or in a new Step. For example, when I am reading an article, I can look up unfamiliar words in new Steps, so I can finish the current article and then look at those definitions later.&lt;/p&gt;
&lt;p&gt;&lt;img alt="New Steps" src="https://lh4.googleusercontent.com/0oWiT3Xjw5XPluesbq_B07Mlvr2nNMy_27YxkiOIsE_gZauVwklXssKV3SE7rhWjoHd58SSae56WqiK9AeG4fHcrrWQQn-LoX-o5P8Cbnb_OFWAcbtEzeIJD"&gt;&lt;/p&gt;
&lt;h2&gt;Manage the Tasks&lt;/h2&gt;
&lt;p&gt;Whenever I complete one Task, I go back to the home screen. At that time, I have the opportunity to merge my history into the original Task or create a new one. In addition, I should have an intuitive interface to easily manage the Tasks:&lt;/p&gt;
&lt;p&gt;&lt;img alt="Manage the Tasks" src="https://lh5.googleusercontent.com/fZevhXmTij2mqmE_lFwg-qkLMlRfqoHsolYj2ngSaanJFsj1KBzGnLgnargdKH-krqe_b5w5PzxfACJL3ePK3uPzR4CqF7mzXwWgOZ_qBbfKSRgxy2wvQRM7"&gt;&lt;/p&gt;
&lt;h2&gt;A New Way to Utilize History&lt;/h2&gt;
&lt;p&gt;History is a seldom used feature. Actually, sorting web pages by visited time simply does not make sense. Sometimes I want to find some pages that I visited before, but it’s often extremely difficult to locate the exact position in history. However, with Single-minded, the history is naturally grouped for each task. It’s easy to guess where the page might be. Also, because I can preserve all history into Tasks if I want, history becomes an useful feature that I can utilize to better manage my Tasks.&lt;/p&gt;
&lt;h2&gt;Never Waiting for Loading&lt;/h2&gt;
&lt;p&gt;The linear browsing makes it easy for the browser to guess which page I will read next. So it should be easy for the browser to preload the pages and completely eliminate the waiting time for me.&lt;/p&gt;
&lt;h2&gt;Final Words&lt;/h2&gt;
&lt;p&gt;I choose to publish this article because I realize that I may not have too much time to polish this idea and implement it. As you can see, this article is still very primitive. But I hope someone may be able to find something valuable in this idea, and help us escape from the distracting dilemma.&lt;/p&gt;</content><category term="browser"></category><category term="Internet"></category></entry></feed>