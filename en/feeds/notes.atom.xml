<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>City of Wings - Notes</title><link href="https://city.shaform.com/en/" rel="alternate"></link><link href="https://city.shaform.com/en/feeds/notes.atom.xml" rel="self"></link><id>https://city.shaform.com/en/</id><updated>2017-10-23T21:30:00+08:00</updated><entry><title>Install TensorFlow and Caffe on Ubuntu 16.04 with Anaconda</title><link href="https://city.shaform.com/en/blog/2017/10/23/install-tensorflow-and-caffe-on-ubuntu.html" rel="alternate"></link><published>2017-10-23T21:30:00+08:00</published><updated>2017-10-23T21:30:00+08:00</updated><author><name>Shaform</name></author><id>tag:city.shaform.com,2017-10-23:/en/blog/2017/10/23/install-tensorflow-and-caffe-on-ubuntu.html</id><summary type="html">&lt;p&gt;Previously I have written about &lt;a href="https://city.shaform.com/en/../blog/2016/10/31/install-tensorflow-with-cuda.html"&gt;在Ubuntu 安裝 TensorFlow 的紀錄 (Installing
TensorFlow on Ubuntu)&lt;/a&gt;.  Years have passed, and even though
Ubuntu is still on 16.04，TensorFlow has
already made great progress.  I've decided to write another post to show how to
install TensorFlow and Caffe with Anaconda.&lt;/p&gt;
&lt;h2&gt;GPU Settings&lt;/h2&gt;
&lt;h3&gt;Basic …&lt;/h3&gt;</summary><content type="html">&lt;p&gt;Previously I have written about &lt;a href="https://city.shaform.com/en/../blog/2016/10/31/install-tensorflow-with-cuda.html"&gt;在Ubuntu 安裝 TensorFlow 的紀錄 (Installing
TensorFlow on Ubuntu)&lt;/a&gt;.  Years have passed, and even though
Ubuntu is still on 16.04，TensorFlow has
already made great progress.  I've decided to write another post to show how to
install TensorFlow and Caffe with Anaconda.&lt;/p&gt;
&lt;h2&gt;GPU Settings&lt;/h2&gt;
&lt;h3&gt;Basic&lt;/h3&gt;
&lt;p&gt;Firstly set integrated video card as the main GPU in the BIOS, and connect your
monitor to the output port of the integrated video card so your Nvidia GPU is
completely dedicated to deep learning computation.&lt;/p&gt;
&lt;h3&gt;Install CUDA&lt;/h3&gt;
&lt;p&gt;Afterwards, download the deb files from &lt;a href="https://developer.nvidia.com/cuda-downloads"&gt;the download page of
CUDA&lt;/a&gt;.  Do not install at this time. We would reboot Ubuntu and
enter &lt;code&gt;Ctrl-Alt-F1&lt;/code&gt; to login via terminal.&lt;/p&gt;
&lt;p&gt;Execute the following command to stop &lt;code&gt;lightdm&lt;/code&gt;.&lt;/p&gt;
&lt;div class="sh-highlight"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="hll"&gt;sudo service lightdm stop
&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;


&lt;/div&gt;
&lt;p&gt;According to &lt;a href="https://gist.github.com/bearpaw/c38ef18ec45ba6548ec0"&gt;this article&lt;/a&gt;, this must be done when you want to
use your Nvidia GPU solely for CUDA. When this is not done, we might not be
able to login to the desktop after CUDA installation.&lt;/p&gt;
&lt;p&gt;So now we would install CUDA 8.0.&lt;/p&gt;
&lt;div class="sh-highlight"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="hll"&gt;sudo dpkg -i cuda-repo-&amp;lt;distro&amp;gt;_&amp;lt;version&amp;gt;_&amp;lt;architecture&amp;gt;.deb
&lt;/span&gt;&lt;span class="hll"&gt;sudo apt update
&lt;/span&gt;&lt;span class="hll"&gt;sudo apt install cuda-8-0
&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;


&lt;/div&gt;
&lt;p&gt;Record which version of nvidia driver is installed and add the PATH to &lt;code&gt;.bashrc&lt;/code&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nb"&gt;export&lt;/span&gt; &lt;span class="nv"&gt;LD_LIBRARY_PATH&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nv"&gt;$LD_LIBRARY_PATH&lt;/span&gt;:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/lib/nvidia-384
&lt;span class="nb"&gt;export&lt;/span&gt; &lt;span class="nv"&gt;CUDA_HOME&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;/usr/local/cuda
&lt;span class="nb"&gt;export&lt;/span&gt; &lt;span class="nv"&gt;PATH&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nv"&gt;$PATH&lt;/span&gt;:/usr/local/cuda/bin
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;where &lt;code&gt;/usr/lib/nvidia-384&lt;/code&gt; should point to the actual version installed.&lt;/p&gt;
&lt;p&gt;Reboot again to confirm that we could login:&lt;/p&gt;
&lt;div class="sh-highlight"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="hll"&gt;sudo reboot
&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;


&lt;/div&gt;
&lt;h2&gt;Setup Anaconda Environment&lt;/h2&gt;
&lt;h3&gt;Install Anaconda&lt;/h3&gt;
&lt;p&gt;Download Python 3 version of Anaconda at the &lt;a href="https://www.anaconda.com/download/#linux"&gt;Anaconda download
page&lt;/a&gt;, and execute the installation command:&lt;/p&gt;
&lt;div class="sh-highlight"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="hll"&gt;bash ~/Downloads/Anaconda3-&lt;span class="o"&gt;{&lt;/span&gt;VERSION&lt;span class="o"&gt;}&lt;/span&gt;-Linux-x86_64.sh
&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;


&lt;/div&gt;
&lt;p&gt;Install Anaconda onto a directory such as &lt;code&gt;$HOME/anaconda3&lt;/code&gt;.&lt;/p&gt;
&lt;h3&gt;Create TensorFlow Environment&lt;/h3&gt;
&lt;p&gt;Activate Anaconda:&lt;/p&gt;
&lt;div class="sh-highlight"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="hll"&gt;&lt;span class="nb"&gt;source&lt;/span&gt; &lt;span class="nv"&gt;$HOME&lt;/span&gt;/anaconda3/bin/activate
&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;


&lt;/div&gt;
&lt;p&gt;And create a new environment named &lt;code&gt;tf&lt;/code&gt;:&lt;/p&gt;
&lt;div class="sh-highlight"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="hll"&gt;conda create -n tf anaconda
&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;


&lt;/div&gt;
&lt;p&gt;Finally activate &lt;code&gt;tf&lt;/code&gt; environment:&lt;/p&gt;
&lt;div class="sh-highlight"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="hll"&gt;&lt;span class="nb"&gt;source&lt;/span&gt; activate tf
&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;


&lt;/div&gt;
&lt;h2&gt;Install TensorFlow&lt;/h2&gt;
&lt;p&gt;Execute this command and &lt;code&gt;tensorflow-gpu&lt;/code&gt;, &lt;code&gt;cudnn&lt;/code&gt;, &lt;code&gt;cudatoolkit&lt;/code&gt; would be
installed automatically.
&lt;div class="sh-highlight" markdown="1"&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="hll"&gt;conda install tensorflow-gpu
&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;


&lt;/div&gt;

&lt;h2&gt;Install Caffe&lt;/h2&gt;
&lt;p&gt;Firstly install the required packages:&lt;/p&gt;
&lt;div class="sh-highlight"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="hll"&gt;sudo apt install build-essential
&lt;/span&gt;&lt;span class="hll"&gt;conda install atlas boost gflags glog hdf5 leveldb lmdb openblas protobuf
&lt;/span&gt;&lt;span class="hll"&gt;conda install -c menpo opencv3
&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;


&lt;/div&gt;
&lt;p&gt;Download Caffe, and create the configuration file.&lt;/p&gt;
&lt;div class="sh-highlight"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="hll"&gt;git clone https://github.com/BVLC/caffe
&lt;/span&gt;&lt;span class="hll"&gt;&lt;span class="nb"&gt;cd&lt;/span&gt; caffe
&lt;/span&gt;&lt;span class="hll"&gt;cp Makefile.config.example Makefile.config
&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;


&lt;/div&gt;
&lt;p&gt;Modify &lt;code&gt;Makefile.config&lt;/code&gt;, the number in &lt;code&gt;python3.6&lt;/code&gt; could be
changed to the current Python version:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;5c5
&lt;span class="o"&gt;&amp;lt;&lt;/span&gt; # USE_CUDNN := 1
&lt;span class="gd"&gt;---&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; USE_CUDNN := 1
21c21
&lt;span class="o"&gt;&amp;lt;&lt;/span&gt; # OPENCV_VERSION := 3
&lt;span class="gd"&gt;---&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; OPENCV_VERSION := 3
25c25
&lt;span class="o"&gt;&amp;lt;&lt;/span&gt; # CUSTOM_CXX := g++
&lt;span class="gd"&gt;---&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; CUSTOM_CXX := /usr/bin/g++-4.9
68,69c68,69
&lt;span class="o"&gt;&amp;lt;&lt;/span&gt; PYTHON_INCLUDE := /usr/include/python2.7 \
&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;       /usr/lib/python2.7/dist-packages/numpy/core/include
&lt;span class="gd"&gt;---&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; # PYTHON_INCLUDE := /usr/include/python2.7 \
&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; #         /usr/lib/python2.7/dist-packages/numpy/core/include
72,75c72,75
&lt;span class="o"&gt;&amp;lt;&lt;/span&gt; # ANACONDA_HOME := $(HOME)/anaconda
&lt;span class="o"&gt;&amp;lt;&lt;/span&gt; # PYTHON_INCLUDE := $(ANACONDA_HOME)/include \
&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;       # $(ANACONDA_HOME)/include/python2.7 \
&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;       # $(ANACONDA_HOME)/lib/python2.7/site-packages/numpy/core/include
&lt;span class="gd"&gt;---&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; ANACONDA_HOME := $(HOME)/anaconda3/envs/tf
&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; PYTHON_INCLUDE := $(ANACONDA_HOME)/include \
&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;       $(ANACONDA_HOME)/include/python3.6m \
&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;       $(ANACONDA_HOME)/lib/python3.6/site-packages/numpy/core/include
83,84c83,84
&lt;span class="o"&gt;&amp;lt;&lt;/span&gt; PYTHON_LIB := /usr/lib
&lt;span class="o"&gt;&amp;lt;&lt;/span&gt; # PYTHON_LIB := $(ANACONDA_HOME)/lib
&lt;span class="gd"&gt;---&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; # PYTHON_LIB := /usr/lib
&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; PYTHON_LIB := $(ANACONDA_HOME)/lib
94c94
&lt;span class="o"&gt;&amp;lt;&lt;/span&gt; INCLUDE_DIRS := $(PYTHON_INCLUDE) /usr/local/include
&lt;span class="gd"&gt;---&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; INCLUDE_DIRS := $(PYTHON_INCLUDE)
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Caffe can now be compiled:&lt;/p&gt;
&lt;div class="sh-highlight"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="hll"&gt;make all
&lt;/span&gt;&lt;span class="hll"&gt;make pycaffe
&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;


&lt;/div&gt;</content><category term="TensorFlow"></category><category term="Caffe"></category><category term="CUDA"></category><category term="Ubuntu"></category></entry><entry><title>Using Caffe for Sentiment Analysis</title><link href="https://city.shaform.com/en/blog/2015/06/06/caffe-sentiment-analysis.html" rel="alternate"></link><published>2015-06-06T11:05:00+08:00</published><updated>2015-06-06T11:05:00+08:00</updated><author><name>Shaform</name></author><id>tag:city.shaform.com,2015-06-06:/en/blog/2015/06/06/caffe-sentiment-analysis.html</id><summary type="html">&lt;p&gt;&lt;a href="http://caffe.berkeleyvision.org/"&gt;Caffe&lt;/a&gt; is a deep learning framework that can be used to
develop neural network models. Although Caffe is usually used
for image classification, it does not prevent us from utilizing it
for other tasks. In this article, we outline the procedure to convert
&lt;a href="http://arxiv.org/abs/1405.4053"&gt;Paragraph Vectors&lt;/a&gt; into the &lt;a href="http://symas.com/mdb/"&gt;LMDB&lt;/a&gt; format that …&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;a href="http://caffe.berkeleyvision.org/"&gt;Caffe&lt;/a&gt; is a deep learning framework that can be used to
develop neural network models. Although Caffe is usually used
for image classification, it does not prevent us from utilizing it
for other tasks. In this article, we outline the procedure to convert
&lt;a href="http://arxiv.org/abs/1405.4053"&gt;Paragraph Vectors&lt;/a&gt; into the &lt;a href="http://symas.com/mdb/"&gt;LMDB&lt;/a&gt; format that Caffe understands, and
create a simple model to train and predict the sentiment for movie reviews.&lt;/p&gt;
&lt;h1&gt;Data Preparation&lt;/h1&gt;
&lt;p&gt;While in the &lt;a href="https://city.shaform.com/en/../blog/2015/03/27/sentiment-analysis.html"&gt;previous post&lt;/a&gt; we use custom Chinese corpus
for sentiment analysis, this time we utilize the scripts provided
by &lt;a href="https://github.com/mesnilgr/iclr15"&gt;mesnilgr/iclr15&lt;/a&gt; to download the &lt;a href="http://ai.stanford.edu/~amaas/data/sentiment/"&gt;Large Movie Review Dataset&lt;/a&gt;
so it's easier to reproduce the results.&lt;/p&gt;
&lt;div class="sh-highlight"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# get mesnilgr/iclr15&lt;/span&gt;
&lt;span class="hll"&gt;git clone https://github.com/mesnilgr/iclr15
&lt;/span&gt;
&lt;span class="hll"&gt;mkdir -p iclr15_run
&lt;/span&gt;&lt;span class="hll"&gt;&lt;span class="nb"&gt;cd&lt;/span&gt; iclr15_run
&lt;/span&gt;
&lt;span class="c1"&gt;# get data&lt;/span&gt;
&lt;span class="hll"&gt;../iclr15/scripts/data.sh
&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;


&lt;/div&gt;
&lt;p&gt;Afterwards, we create the &lt;a href="http://arxiv.org/abs/1405.4053"&gt;Paragraph Vectors&lt;/a&gt; for each review. Paragraph
Vectors are fixed-dimensional distributed representations for texts. Once we
convert each review into a vector, we could easily feed it into a neural network.&lt;/p&gt;
&lt;div class="sh-highlight"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# extract the part to create paragraph vectors from iclr15 scripts&lt;/span&gt;
&lt;span class="hll"&gt;sed -e &lt;span class="s1"&gt;&amp;#39;/liblinear/,$d&amp;#39;&lt;/span&gt; ../iclr15/scripts/paragraph.sh &amp;gt; paragraph.sh
&lt;/span&gt;
&lt;span class="c1"&gt;# start creating the vectors&lt;/span&gt;
&lt;span class="hll"&gt;chmod +x paragraph.sh
&lt;/span&gt;&lt;span class="hll"&gt;./paragraph.sh
&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;


&lt;/div&gt;
&lt;p&gt;Finally, we copy the resulting files.&lt;/p&gt;
&lt;div class="sh-highlight"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# copy the vectors&lt;/span&gt;
&lt;span class="hll"&gt;&lt;span class="nb"&gt;cd&lt;/span&gt; word2vec
&lt;/span&gt;&lt;span class="hll"&gt;cp full-train.txt test.txt ../../
&lt;/span&gt;&lt;span class="hll"&gt;&lt;span class="nb"&gt;cd&lt;/span&gt; ../../
&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;


&lt;/div&gt;
&lt;h1&gt;Converting the Input Format&lt;/h1&gt;
&lt;p&gt;We now have two files: &lt;code&gt;full-train.txt&lt;/code&gt; and &lt;code&gt;test.txt&lt;/code&gt; for training and testing
respectively. These files use &lt;a href="https://github.com/cjlin1/libsvm/blob/master/README"&gt;LIBSVM data format&lt;/a&gt;, which can
not be used with Caffe directly. Therefore, we create a script to convert the files.&lt;/p&gt;
&lt;p&gt;We will use utilities provided by &lt;a href="http://caffe.berkeleyvision.org/installation.html#python-andor-matlab-caffe-optional"&gt;Pycaffe&lt;/a&gt; to do the conversion; be sure to install
all the dependencies and Pycaffe itself. Notice that currently Pycaffe does not work
well on Python 3, so we'll use Python 2.7 here. If you don't want to install Pycaffe
system-wide. You could also manually set the &lt;code&gt;PYTHONPATH&lt;/code&gt; variable as follows.&lt;/p&gt;
&lt;div class="sh-highlight"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="hll"&gt;&lt;span class="nb"&gt;export&lt;/span&gt; &lt;span class="nv"&gt;PYTHONPATH&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="si"&gt;${&lt;/span&gt;&lt;span class="nv"&gt;PYTHONPATH&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;:caffe-directory/python/
&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;


&lt;/div&gt;
&lt;p&gt;In addition, install the &lt;a href="http://lmdb.readthedocs.org/en/release/"&gt;py-lmdb&lt;/a&gt; Python package.&lt;/p&gt;
&lt;div class="sh-highlight"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="hll"&gt;sudo pip install lmdb
&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;


&lt;/div&gt;
&lt;p&gt;Each line in the input file begins with a label followed by a 100-dimensional array.
So we extract the data using a simple Python routine.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;random&lt;/span&gt;

&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;np&lt;/span&gt;

&lt;span class="n"&gt;num_of_dims&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;100&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;load_data&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;path&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;items&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;
    &lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="nb"&gt;open&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;path&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;l&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="n"&gt;tokens&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;l&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;rstrip&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;split&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
            &lt;span class="n"&gt;label&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;int&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tokens&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
            &lt;span class="c1"&gt;# change label `-1&amp;#39; to `0&amp;#39;&lt;/span&gt;
            &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;label&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                &lt;span class="n"&gt;label&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;
            &lt;span class="c1"&gt;# ignore the index since we already know the format&lt;/span&gt;
            &lt;span class="n"&gt;arr&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nb"&gt;float&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dim&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;split&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;:&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;dim&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;tokens&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;:]]&lt;/span&gt;
            &lt;span class="n"&gt;items&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;label&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;arr&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;

    &lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shuffle&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;items&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="n"&gt;Y&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;_&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;items&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
    &lt;span class="n"&gt;X&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;_&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;items&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
    &lt;span class="n"&gt;X&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;reshape&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Y&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;num_of_dims&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;

    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Y&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;There is a well-written tutorial on creating LMDB file on
&lt;a href="http://deepdish.io/2015/04/28/creating-lmdb-in-python/"&gt;Creating an LMDB database in Python&lt;/a&gt;, and we'll adopt
a similar procedure. The only difference is that we are using &lt;code&gt;floats&lt;/code&gt;
for the data, so we'll just use &lt;code&gt;array_to_datum&lt;/code&gt; to create the &lt;code&gt;Datum&lt;/code&gt;
for us.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;lmdb&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;caffe.io&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;array_to_datum&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;save_data&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;path&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Y&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt; 
    &lt;span class="n"&gt;num&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;prod&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;itemsize&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;dtype&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;dtype&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;itemsize&lt;/span&gt;
    &lt;span class="c1"&gt;# set a reasonable upper limit for database size&lt;/span&gt;
    &lt;span class="n"&gt;map_size&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;10240&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mi"&gt;1024&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;num&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;itemsize&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt; 
    &lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;save {} instances...&amp;#39;&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;num&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="n"&gt;env&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;lmdb&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;open&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;path&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;map_size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;map_size&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;enumerate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;zip&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Y&lt;/span&gt;&lt;span class="p"&gt;)):&lt;/span&gt;
        &lt;span class="n"&gt;datum&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;array_to_datum&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;str_id&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;{:08}&amp;#39;&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

        &lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="n"&gt;env&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;begin&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;write&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;txn&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="n"&gt;txn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;put&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;str_id&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;datum&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;SerializeToString&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Using the complete &lt;a href="https://github.com/shaform/experiments/blob/master/caffe_sentiment_analysis/convert.py"&gt;convert.py&lt;/a&gt; script, we convert both
training and testing files into LMDB format.&lt;/p&gt;
&lt;div class="sh-highlight"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="hll"&gt;python convert.py full-train.txt movie-train-lmdb
&lt;/span&gt;&lt;span class="hll"&gt;python convert.py test.txt movie-test-lmdb
&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;


&lt;/div&gt;
&lt;h1&gt;Creating a Caffe Model&lt;/h1&gt;
&lt;p&gt;Finally, we create a simple NN model with &lt;a href="https://github.com/shaform/experiments/blob/master/caffe_sentiment_analysis/nn.prototxt"&gt;nn.prototxt&lt;/a&gt; and &lt;a href="https://github.com/shaform/experiments/blob/master/caffe_sentiment_analysis/nn_solver.prototxt"&gt;nn_solver.prototxt&lt;/a&gt;. Execute the
Caffe command line tool and we obtain the following results.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ caffe train --solver=nn_solver.prototxt

Iteration 10000, loss = 0.142478
Iteration 10000, Testing net (#0)
    Test net output #0: accuracy = 0.88364
    Test net output #1: loss = 0.284636 (* 1 = 0.284636 loss)
Optimization Done.
&lt;/pre&gt;&lt;/div&gt;


&lt;h1&gt;Source Code&lt;/h1&gt;
&lt;p&gt;The relevant source code is on &lt;a href="https://github.com/shaform/experiments/blob/master/caffe_sentiment_analysis/"&gt;shaform/experiments/caffe_sentiment_analysis&lt;/a&gt;.&lt;/p&gt;</content><category term="word2vec"></category><category term="Caffe"></category><category term="sentiment analysis"></category><category term="deep learning"></category></entry></feed>